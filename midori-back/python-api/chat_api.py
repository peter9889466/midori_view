from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import os
import pandas as pd
import logging
from dotenv import load_dotenv
from openai import OpenAI

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# FastAPI ì•± ìƒì„±
app = FastAPI(title="GPT-4o mini CSV ChatBot", version="3.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:8088", "http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ìš”ì²­/ì‘ë‹µ ëª¨ë¸
class ChatRequest(BaseModel):
    message: str

class ChatResponse(BaseModel):
    response: str
    success: bool = True
    session_id: str = "default"

# ================================
# ì „ì—­ ë³€ìˆ˜
# ================================
csv_data = None
csv_loaded = False
knowledge_base = ""

def load_csv_file():
    """CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°"""
    global csv_data, csv_loaded, knowledge_base
    
    csv_file_path = "data/Merged_DataSet.csv"
    
    try:
        if not os.path.exists(csv_file_path):
            print("âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤:", csv_file_path)
            return False
        
        # CSV íŒŒì¼ ì½ê¸° (ì¸ì½”ë”© ì²˜ë¦¬)
        try:
            csv_data = pd.read_csv(csv_file_path, encoding='utf-8')
            print("âœ… UTF-8ë¡œ íŒŒì¼ ì½ê¸° ì„±ê³µ")
        except:
            try:
                csv_data = pd.read_csv(csv_file_path, encoding='cp949')
                print("âœ… CP949ë¡œ íŒŒì¼ ì½ê¸° ì„±ê³µ")
            except:
                csv_data = pd.read_csv(csv_file_path, encoding='euc-kr')
                print("âœ… EUC-KRë¡œ íŒŒì¼ ì½ê¸° ì„±ê³µ")
        
        print(f"ğŸ“Š CSV ë°ì´í„°: {len(csv_data)}í–‰, {len(csv_data.columns)}ì—´")
        print(f"ğŸ“‹ ì»¬ëŸ¼: {list(csv_data.columns)}")
        
        # ì§€ì‹ë² ì´ìŠ¤ ìƒì„±
        knowledge_base = create_knowledge_base()
        print(f"ğŸ§  ì§€ì‹ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ: {len(knowledge_base)}ê¸€ì")
        
        csv_loaded = True
        return True
        
    except Exception as e:
        print(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def create_knowledge_base():
    """CSV ë°ì´í„°ë¥¼ AIìš© ì§€ì‹ë² ì´ìŠ¤ë¡œ ë³€í™˜"""
    if csv_data is None:
        return ""
    
    kb_parts = []
    kb_parts.append("=== ì¹œí™˜ê²½ ì œí’ˆ ìˆ˜ì¶œì… ë°ì´í„° ===\n")
    
    for index, row in csv_data.iterrows():
        question = str(row.get('ì§ˆë¬¸', '')).strip()
        answer = str(row.get('ë‹µë³€', '')).strip()
        
        if question and answer and question != 'nan' and answer != 'nan':
            kb_parts.append(f"ë°ì´í„° {index + 1}:")
            kb_parts.append(f"Q: {question}")
            kb_parts.append(f"A: {answer}")
            kb_parts.append("")
    
    return "\n".join(kb_parts)

def ask_gpt4_mini(user_question):
    """GPT-4o minië¡œ ì „ì²´ ë°ì´í„° ë¶„ì„"""
    
    if not os.getenv("OPENAI_API_KEY"):
        return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        system_prompt = f"""ë‹¹ì‹ ì€ ì¹œí™˜ê²½ ì œí’ˆ ìˆ˜ì¶œì… ë°ì´í„° ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ëª¨ë“  CSV ë°ì´í„°ì…ë‹ˆë‹¤:

{knowledge_base}
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìœ„ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‹µë³€ ê·œì¹™:
1. ë°ì´í„°ì— ìˆëŠ” ì •ë³´ë¥¼ ì •í™•íˆ ë¶„ì„
2. ìˆ˜ì¹˜ë‚˜ êµ­ê°€ëª…ì€ ì •í™•íˆ ì¸ìš©
3. ì—¬ëŸ¬ ë°ì´í„°ë¥¼ ë¹„êµí•˜ì—¬ ì¸ì‚¬ì´íŠ¸ ì œê³µ
4. ì—†ëŠ” ì •ë³´ëŠ” "í•´ë‹¹ ì •ë³´ ì—†ìŒ"ì´ë¼ê³  ëª…ì‹œ
5. ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…
6. ì£¼ì–´ì§„ ë°ì´í„°ì™€ ìƒê´€ì´ ì—†ëŠ” ì§ˆë¬¸ì´ë¼ê³  ìƒê°ë  ë•ŒëŠ” ë²”ìœ„ ë°–ì˜ ì§ˆë¬¸ì´ë¼ê³  ëŒ€ë‹µ.
"""

        print("ğŸ¤– GPT-4.1 ë¶„ì„ ì¤‘...")
        
        response = client.chat.completions.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_question}
            ],
            temperature=0.2,
            top_p=1.0,
            frequency_penalty=0.4,
            presence_penalty=0.3,
            max_tokens=1000
        )
        
        answer = response.choices[0].message.content.strip()
        print(f"âœ… ë‹µë³€ ì™„ë£Œ: {len(answer)}ê¸€ì")
        
        return answer
        
    except Exception as e:
        print(f"âŒ AI ì˜¤ë¥˜: {e}")
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def simple_chat(message):
    """ê¸°ë³¸ ëŒ€í™” ì²˜ë¦¬"""
    message_lower = message.lower()
    
    if "ì•ˆë…•" in message_lower or "hello" in message_lower:
        if csv_loaded:
            return f"""ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š

ì¹œí™˜ê²½ ì œí’ˆ ìˆ˜ì¶œì… ë°ì´í„° ë¶„ì„ ì±—ë´‡ì…ë‹ˆë‹¤.

í˜„ì¬ 2024ë…„ 6ì›”ë¶€í„° 2025ë…„ 5ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.

í•´ë‹¹ ë²”ìœ„ ë‚´ì—ì„œ ììœ ë¡­ê²Œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!

ì˜ˆ: "ì„¸ì œ ìˆ˜ì¶œ í˜„í™©ì€?"
   "ìˆ˜ì¶œì•¡ì´ ê°€ì¥ í° ì œí’ˆì€?"
   "ë² íŠ¸ë‚¨ì— ìˆ˜ì¶œí•˜ëŠ” ì œí’ˆë“¤ ë¹„êµí•´ì¤˜" """
        else:
            return "ì•ˆë…•í•˜ì„¸ìš”! ë°ì´í„° ë¡œë”© ì¤‘ì…ë‹ˆë‹¤."
    
    elif "ë„ì›€" in message_lower or "help" in message_lower:
        return f"""ğŸ“š ì‚¬ìš©ë²• ì•ˆë‚´

ğŸ¤– GPT-4.1 ê¸°ë°˜ ë°ì´í„° ë¶„ì„ ì±—ë´‡
ğŸ“Š í˜„ì¬ {len(csv_data) if csv_loaded else 0}ê°œ ë°ì´í„° ë¶„ì„ ê°€ëŠ¥
ë°ì´í„° ë²”ìœ„ : 2024ë…„ 6ì›” ~ 2025ë…„ 5ì›”

ğŸ’¡ ì´ëŸ° ì§ˆë¬¸ë“¤ì„ í•´ë³´ì„¸ìš”:
â€¢ "â—‹â—‹ ì œí’ˆ ìˆ˜ì¶œ í˜„í™©ì€?"
â€¢ "ê°€ì¥ ë§ì´ ìˆ˜ì¶œë˜ëŠ” ì œí’ˆì€?"
â€¢ "ì¤‘êµ­ê³¼ ì¼ë³¸ ìˆ˜ì¶œ ë¹„êµí•´ì¤˜"
â€¢ "ì „ì²´ ë°ì´í„°ë¥¼ ìš”ì•½í•´ì¤˜"

ì „ì²´ ë°ì´í„°ë¥¼ í•œë²ˆì— ë¶„ì„í•´ì„œ ì •í™•í•œ ë‹µë³€ì„ ë“œë ¤ìš”! ğŸš€"""
    
    elif "ê°ì‚¬" in message_lower or "ê³ ë§ˆì›Œ" in message_lower:
        return "ì²œë§Œì—ìš”! ğŸ˜Š ë‹¤ë¥¸ ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”."
    
    elif "í…ŒìŠ¤íŠ¸" in message_lower:
        return "í…ŒìŠ¤íŠ¸ ì„±ê³µ! ğŸ‰ GPT-4.1 ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    
    elif any(word in message_lower for word in ["ë°ì´í„°", "ì •ë³´", "í™•ì¸"]):
        if csv_loaded:
            return f"""ğŸ“Š í˜„ì¬ ë°ì´í„° ìƒíƒœ:

â€¢ ì´ {len(csv_data)}ê°œ ì§ˆë¬¸-ë‹µë³€ ìŒ
â€¢ ì»¬ëŸ¼: {', '.join(csv_data.columns)}
â€¢ ëª¨ë¸: GPT-4.1 (128K í† í°)
â€¢ ìƒíƒœ: ì „ì²´ ë°ì´í„° ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ âœ…

êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ì „ì²´ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì„œ ë‹µë³€ë“œë ¤ìš”!"""
        else:
            return "ë°ì´í„° ë¡œë”© ì¤‘ì…ë‹ˆë‹¤."
    
    else:
        return None

# ================================
# API ì—”ë“œí¬ì¸íŠ¸
# ================================

@app.on_event("startup")
async def startup_event():
    print("ğŸš€ GPT-4o mini ì±—ë´‡ ì„œë²„ ì‹œì‘!")
    os.makedirs("data", exist_ok=True)
    
    if load_csv_file():
        print("âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
    else:
        print("âš ï¸ data/QA_Refinement.csv íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

@app.get("/")
async def root():
    return {
        "message": "GPT-4.1 CSV ë¶„ì„ ì±—ë´‡",
        "version": "3.0.0",
        "model": "GPT-4.1",
        "csv_loaded": csv_loaded,
        "data_rows": len(csv_data) if csv_loaded else 0
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "model": "GPT-4.1",
        "csv_loaded": csv_loaded,
        "data_rows": len(csv_data) if csv_loaded else 0,
        "ai_ready": bool(os.getenv("OPENAI_API_KEY")),
        "message": "GPT-4.1 ì‹œìŠ¤í…œ ì •ìƒ"
    }

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """ë©”ì¸ ì±„íŒ… ì²˜ë¦¬"""
    try:
        user_message = request.message
        print(f"ğŸ“¥ ì§ˆë¬¸: {user_message}")
        
        if not csv_loaded:
            return ChatResponse(
                response="ë°ì´í„° ë¡œë”© ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!",
                success=False
            )
        
        # ê¸°ë³¸ ëŒ€í™” í™•ì¸
        simple_response = simple_chat(user_message)
        
        if simple_response:
            ai_response = simple_response
        else:
            # GPT-4o mini ë¶„ì„
            ai_response = ask_gpt4_mini(user_message)
        
        print(f"ğŸ“¤ ë‹µë³€ ì™„ë£Œ")
        
        return ChatResponse(
            response=ai_response,
            success=True
        )
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return ChatResponse(
            response=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            success=False
        )

@app.get("/data-info")
async def get_data_info():
    """ë°ì´í„° ì •ë³´ í™•ì¸"""
    if not csv_loaded:
        return {"error": "ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
    
    return {
        "model": "GPT-4.1",
        "total_rows": len(csv_data),
        "columns": list(csv_data.columns),
        "knowledge_base_size": len(knowledge_base),
        "estimated_tokens": int(len(knowledge_base.split()) * 1.3),
        "sample_questions": [
            str(csv_data.iloc[i].get('ì§ˆë¬¸', '')) 
            for i in range(min(5, len(csv_data)))
            if str(csv_data.iloc[i].get('ì§ˆë¬¸', '')) != 'nan'
        ]
    }

@app.get("/model-info")
async def get_model_info():
    """ëª¨ë¸ ì •ë³´"""
    return {
        "model": "GPT-4.1",
        "context_window": "128K tokens",
        "max_output": "2000 tokens",
        "temperature": 0.3,
        "features": [
            "ì „ì²´ CSV ë°ì´í„° ë™ì‹œ ë¶„ì„",
            "í† í° ì œí•œ ì—†ìŒ",
            "ì¢…í•© ë¹„êµ ë¶„ì„",
            "ì •í™•í•œ ìˆ˜ì¹˜ ì¸ìš©"
        ]
    }

# ================================
# ì„œë²„ ì‹¤í–‰
# ================================
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ GPT-4.1 CSV ì±—ë´‡ ì‹œì‘")
    print("ğŸ“¡ í¬íŠ¸: 8000")
    print("ğŸ§  GPT-4o mini (128K í† í°)")
    print("ğŸ“Š ì „ì²´ ë°ì´í„° ë™ì‹œ ë¶„ì„")
    print("=" * 60)
    
    uvicorn.run(
        "chat_api:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )